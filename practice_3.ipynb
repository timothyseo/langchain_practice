{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM의 답변을 원하는 형태로 조정하는 Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실무에서 LLM을 API로 활용하면서 구조화된 답변을 받고 싶을때 대개의 LLM은 문장을 생성하는 것에 특화되어 있어 정해진 형식으로 답변을 받는것은 어렵다.  \n",
    "이런 경우, 프롬프트 엔지니어링이 일반적인 해결책이다.  \n",
    "영화 추천 AI앱을 만든다고 했을 때, AI가 추천해주는 영화 제목들은 일반 텍스트가 아니라 리스트 형태로 보여줘야 한다.   \n",
    "이를 가정하고 ChatPromptTemplate 기반 프롬프트 엔지니어링 후 LLM API로 리스트 형태의 답변을 받아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"세븐\", \"양들의 침묵\", \"기생충\"]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from langchain.prompts import HumanMessagePromptTemplate \n",
    "from langchain_core.messages import SystemMessage \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "# ChatPromptTemplate에 SystemMessage로 LLM의 역할과 출력 형식 지정\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"너는 영화 전문가 AI야. 사용자가 원하는 장르의 영화를 리스트 형태로 추천해줘.\"\n",
    "                'ex) Query: SF영화 3개 추천해줘 / 답변: [\"인터스텔라\", \"스페이스오디세이\", \"혹성탈출\"]'\n",
    "            )\n",
    "        ),\n",
    "         HumanMessagePromptTemplate.from_template(\"{text}\")             \n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(text=\"스릴러 영화 3개를 추천해줘.\")\n",
    "answer = llm.invoke(messages)\n",
    "result = answer.content \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SystemMessage에서 정의한대로 리스트 형태로 출력했다.  \n",
    "JSON이나 Pydantic 같은 더 복잡한 구조의 답변을 받기 위해서는 Output Parser를 활용해서 정해진 형식의 답변을 출력할 수 있다.  \n",
    " - CSV 파서, Datetime 파서, JSON 파서, Pydantic 파서  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['스타워즈', '매트릭스', '인터스텔라']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쉼표로 구분된 리스트를 출력하는 CSV 파서\n",
    "\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "# csv파서 선언\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "# csv 파서 작동을 위한 형식 지정 프롬프트 로드\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# 프롬프트 템플릿의 partial_variables에 csv 형식 지정 프롬프트 주입\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List {number} {subject}. answer in Korean \\n{format_instructions}\",\n",
    "    input_variables=[\"subject\", \"number\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# 프롬프트 탬플릿-모델-Output Parser를 체인으로 연결\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"subject\":\"SF영화\", \"number\":\"3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-15 14:15:16.000001\n"
     ]
    }
   ],
   "source": [
    "# 날짜 형식만 출력하는 datetime 파서 \n",
    "\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "template = \"\"\" \n",
    "    Answer the user's question: {question}\n",
    "    \n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template, \n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "chain = prompt | model | output_parser \n",
    "output = chain.invoke({\"question\": \"chatgpt는 언제 개발됐어?\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1829-05-26T00:05:16.509109Z, 1079-06-15T09:41:33.917568Z, 1970-04-07T20:30:42.571030Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'continent': '아프리카', 'population': 17000000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시스템 통신의 기본 형식을 위한 JSON 파서 \n",
    "\n",
    "from typing import List \n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "# 원하는 데이터 구조 정의 \n",
    "class Country(BaseModel):\n",
    "    continent: str = Field(description=\"사용자가 물어본 나라가 속한 대륙\")\n",
    "    population: int = Field(description=\"사용자가 물어본 나라의 인구 수(int 형식)\")\n",
    "# and a query intented to prompt a language model to populate the data structure \n",
    "country_query = \"차드는 어떤 나라야?\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template \n",
    "parser = JsonOutputParser(pydantic_object=Country) \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "chain = prompt | model | parser \n",
    "\n",
    "chain.invoke({'query': country_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
