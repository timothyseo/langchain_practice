{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭체인을 통한 LLM 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, I am a large language model, trained by Google. I am designed to communicate and generate human-like text in response to a wide range of prompts and questions.  Essentially, I am here to help you with language-based tasks.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-100ca055-063a-4f17-bdb3-3cfd9a8cae8f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 50, 'total_tokens': 58, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langchain으로 모델 불러오기\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-thinking-exp-01-21\", # model_name is wrong. \n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    ")\n",
    "\n",
    "chat.invoke(\"Please introduce yourself in three sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # claude로 모델 API 불러오기\n",
    "# import anthropic\n",
    "\n",
    "# anthropic.Anthropic(\n",
    "#     api_key=\"YOUR_API_KEY\").messages.create(\n",
    "#         model=\"claude-3-7-sonnet-latest\",\n",
    "#         max_tokens=1024,\n",
    "#         messages=[\n",
    "#             {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # openai chatgpt 모델 API 호출\n",
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "# client.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini-2024-07-18\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\",\n",
    "#         \"content\": \"Who won the world series in 2020?\"}\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요. 저는 여러분을 돕기 위해 개발된 인공지능 모델입니다. 만나서 반갑습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-058e9d3d-7755-4357-8309-c6c3e6c88d49-0', usage_metadata={'input_tokens': 11, 'output_tokens': 22, 'total_tokens': 33, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"한국어로 자기 소개해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are helpful AI bot. Your name is Max.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm fine, thank you.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 연습하기\n",
    "# ChatPromptTemplate 모듈 (대화 형식 만들기)\n",
    "# SystemMessage로 사용자에게 유용한 챗봇이 되도록 역할 부여하고 이름을 지을 수 있도록 처리\n",
    "# HumanMessage와 AIMessage로 서로 안부를 묻고 답하는 대화 히스토리를 전달하여 대화의 맥락 부여\n",
    "# {user_input} 매개변수를 통ㄷ해 사용자의 입력값을 HumanMessage로 받아들여 LLM이 답할 수 있게 설정\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        #SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are helpful AI bot. Your name is {name}.\"),\n",
    "        #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm fine, thank you.\"),\n",
    "        #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "message = prompt_template.format_messages(name=\"Max\", user_input=\"What is your name?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SystemMessage : LLM에게 지속적으로 부여되는 프롬프트. 이걸 LLM에게 전달하면 LLM은 주어진 HumanMessage에 대해 SystemMessage의 지침대로 행동한다.  \n",
    "HumanMessage : LLM에게 전달하는 사용자의 메세지  \n",
    "AIMessage : LLM이 출력한 메세지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I don't like eating seaweed.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 두번째 탬플릿\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "    ]\n",
    ")\n",
    "message = chat_template.format_messages(text=\"I don't like eating seaweed.\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 사이버 보안은 디지털 세계를 안전하게 지키고 개인 정보 및 자산을 보호하는 데 필수적이기 때문입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 사이버 보안은 디지털 세계를 안전하게 지키고 개인 정보 및 자산을 보호하는 데 필수적이기 때문입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 사이버보안은 우리의 디지털 자산과 개인 정보를 사이버 위협으로부터 보호하여 안전하게 지켜주기 때문에 중요합니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 사이버보안은 개인 정보 유출, 재산 피해, 사회 혼란 등 사이버 위협으로부터 우리를 보호하여 안전한 디지털 세상을 만드는 데 필수적이기 때문입니다.\n"
     ]
    }
   ],
   "source": [
    "# LLM의 Temperature\n",
    "# 서로 다른 temperature 설정으로 답변의 차이 비교하기\n",
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "# temperature = 0\n",
    "model_1_1 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key) \n",
    "model_1_2 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "# temperature = 1\n",
    "model_2_1 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=1, google_api_key=api_key)\n",
    "model_2_2 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=1, google_api_key=api_key)\n",
    "\n",
    "model_list = [model_1_1, model_1_2, model_2_1, model_2_2]\n",
    "\n",
    "for i in model_list:\n",
    "    answer = i.invoke(\"왜 사이버보안이 중요한지 한 문장으로 설명해줘.\")\n",
    "    print(\"-\"*100)\n",
    "    print(\">>>\", answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 실행결과를 보면 temerature 0은 똑같은 답변을 출력하지만 값을 1로 설정한 경우 다소 다른 답변을 출력한다.   \n",
    "이처럼 temparature 매개변수는 LLM의 답변 스타일을 조정한다.  \n",
    "LLM은 마치 문장 완성 게임을 하는것처럼 주어진 문장과 단어를 보고 다음에 어떤 단어가 올 지 예측하는데, 무작위로 고르는게 아니라 각 단어가 나올 확률을 계산한다.  \n",
    "가장 그럴듯한 단어부터 덜 그럴듯한 단어까지 순위를 매긴다.  \n",
    "여기서 temperature 매개변수가 작동한다. LLM의 '대담성'을 조절하는 도구다. temparature를 낮추면 답변의 일관성을, 높이면 무작위성을 높인다.  \n",
    "즉, 단어 출현 확률 분포를 조절해서 특정 단어의 출현 확률을 높이면(temperature가 낮으면) 안전한 답변을,  \n",
    "다른 단어들과 출현 확률을 큰 차이가 없도록 조정하면(temperature가 높으면) 모험적인 답변을 하게 된다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 달\n",
      "\n",
      "밤하늘 검은 도화지 위에\n",
      "하얀 달이 떠오르네\n",
      "\n",
      "차가운 듯 따스한 달빛은\n",
      "세상을 부드럽게 감싸네\n",
      "\n",
      "고요한 밤, 홀로 빛나는 달은\n",
      "외로운 나의 마음을 비추네\n",
      "\n",
      "차고 이지러지는 모습\n",
      "변함없이 밤을 지키네\n",
      "\n",
      "어둠 속에서 길을 잃을 때\n",
      "은은한 빛으로 나를 위로하네"
     ]
    }
   ],
   "source": [
    "# 답변 스트리밍\n",
    "# 스트리밍이란? 사용자 질문에 마치 사람이 타이핑하는것처럼 한 단어씩 생성하는 과정을 보여주는다. \n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "for chunk in chat.stream(\"달에 관한 시를 써줘.\"): # chat으로 선언한 모델에 stream()함수를 실행하여 모델의 답변 청크를 연속적으로 받아온다.\n",
    "    print(chunk.content, end=\"\", flush=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "화면에 실시간으로 답변이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 양자역학은 **아주 작은 세계(원자, 전자 등)를 다루는 물리 법칙**인데, 이 세계에서는 **에너지, 운동량 등이 불연속적인 값(양자화)을 가지고, 입자와 파동의 성질을 동시에 가지며, 미래를 정확히 예측하는 대신 확률적으로만 예측할 수 있습니다.**\n",
      "\n",
      "**좀 더 간단히 말하면, 아주 작은 세계의 '이상하고 확률적인' 물리 법칙입니다.**\n",
      "실행 시간: 6.7631초\n"
     ]
    }
   ],
   "source": [
    "# 응답 캐싱하여 더 빠르게 응답받기\n",
    "\n",
    "import time\n",
    "from langchain.globals import set_llm_cache # 캐시 메모리 라이브러리 호출\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache()) # 캐시 메모리 설정\n",
    "\n",
    "# 시간 측정을 위한 코드 추가\n",
    "start_time = time.time()\n",
    "response = chat.invoke(\"양자역학을 한마디로 설명해줘.\")\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"응답:\", response.content)\n",
    "print(f\"실행 시간: {end_time - start_time:.4f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답변 속도를 빠르게 하기 위해 이전 응답을 캐싱해줘서 이건 답변을 임시 저장소(캐시 메모리)에 저장했다가 똑같은 질문을 했을때 캐시 메모리에 저장해둔 이전의 답변을 검색하여 그대로 출력  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "캐시 사용 후 시간 측정:\n",
      "응답: 양자역학은 **아주 작은 세계(원자, 전자 등)를 다루는 물리 법칙**인데, 이 세계에서는 **에너지, 운동량 등이 불연속적인 값(양자화)을 가지고, 입자와 파동의 성질을 동시에 가지며, 미래를 정확히 예측하는 대신 확률적으로만 예측할 수 있습니다.**\n",
      "\n",
      "**좀 더 간단히 말하면, 아주 작은 세계의 '이상하고 확률적인' 물리 법칙입니다.**\n",
      "실행 시간: 0.0010초\n"
     ]
    }
   ],
   "source": [
    "# 캐시된 응답 시간 측정\n",
    "\n",
    "print(\"\\n캐시 사용 후 시간 측정:\")\n",
    "start_time = time.time()\n",
    "response = chat.invoke(\"양자역학을 한마디로 설명해줘.\")  # 동일한 질문으로 캐시된 응답 확인\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"응답:\", response.content)\n",
    "print(f\"실행 시간: {end_time - start_time:.4f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall practice for today\n",
    "1. 모델 호출\n",
    "2. ChatpromptTemplate으로 SystemMessage, HumanMessage 프롬프트 설정\n",
    "3. stream() 함수를 통한 답변 스트리밍 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 랭체인(LangChain) RAG 학습 계획 (6주)\n",
      "\n",
      "안녕하세요! 랭체인을 활용한 RAG (Retrieval-Augmented Generation) 학습 계획을 수립해 드릴게요. 6주 동안 RAG의 기본 개념부터 랭체인을 활용한 심화 내용까지 체계적으로 학습할 수 있도록 구성했습니다.  각 주차별 목표, 학습 내용, 실습 과제, 참고 자료를 포함하고 있으며, 개인의 학습 속도에 맞춰 조절 가능합니다.\n",
      "\n",
      "**학습 목표:**\n",
      "\n",
      "* RAG의 기본 원리 및 작동 방식 이해\n",
      "* 랭체인의 핵심 모듈 및 기능 숙지\n",
      "* 랭체인을 활용하여 실제 RAG 시스템 구축 능력 함양\n",
      "* 다양한 RAG 활용 사례 학습 및 응용 능력 강화\n",
      "\n",
      "**주차별 학습 계획:**\n",
      "\n",
      "**1주차: RAG 기초 다지기 (RAG 개념 및 필요성 이해)**\n",
      "\n",
      "* **목표:** RAG의 기본적인 개념과 등장 배경, 그리고 왜 필요한 기술인지 이해합니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG란 무엇인가?**: 정의, 작동 방식, 장점 및 단점 학습\n",
      "    * **기존 생성 모델의 한계**:  생성 모델의 환각(Hallucination) 문제점과 RAG의 필요성 이해\n",
      "    * **검색(Retrieval)과 생성(Generation)의 결합**:  각 단계별 역할 및 상호 작용 방식 학습\n",
      "    * **RAG의 다양한 활용 분야**:  챗봇, 문서 요약, 질의응답 등 실제 적용 사례 탐색\n",
      "* **실습 과제:**\n",
      "    * RAG 관련 블로그 글 또는 논문 2-3개 읽고 핵심 내용 요약\n",
      "    * RAG를 활용할 수 있는 아이디어 3가지 이상 발상하고 간단하게 설명\n",
      "* **참고 자료:**\n",
      "    * RAG 관련 블로그 글 (예: [검색 증강 생성(RAG)이란 무엇일까요? - AWS](https://aws.amazon.com/ko/what-is/retrieval-augmented-generation-rag/))\n",
      "    * RAG 관련 유튜브 영상 (예: [RAG(Retrieval Augmented Generation) 쉽게 이해하기](https://www.youtube.com/watch?v=wmddn_gOQ-Y))\n",
      "    * RAG 관련 논문 (예: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks)\n",
      "\n",
      "**2주차: 랭체인(LangChain) 첫걸음 (기본 개념 및 환경 설정)**\n",
      "\n",
      "* **목표:** 랭체인의 기본적인 개념을 이해하고, 학습 환경을 설정합니다. 랭체인의 핵심 모듈과 사용법을 익히기 위한 준비 단계입니다.\n",
      "* **학습 내용:**\n",
      "    * **랭체인 소개**: 랭체인의 특징, 장점, 주요 기능 학습\n",
      "    * **랭체인 설치 및 개발 환경 설정**:  Python 환경 설정, 랭체인 라이브러리 설치\n",
      "    * **랭체인의 기본 구성 요소**:  Models, Prompts, Chains, Indexes, Memory, Agents 등 핵심 모듈 소개 및 역할 이해\n",
      "    * **간단한 랭체인 예제 실행**:  LLM 호출, 프롬프트 템플릿 사용 등 기본적인 랭체인 코드 실습\n",
      "* **실습 과제:**\n",
      "    * 랭체인 개발 환경 설정 완료 (Python, Langchain 라이브러리 설치)\n",
      "    * 랭체인 공식 문서 또는 튜토리얼 따라 간단한 예제 코드 실행 및 결과 확인\n",
      "    * 랭체인 주요 모듈 (Models, Prompts, Chains) 각각의 역할과 간단한 사용법 정리\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 ([https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction))\n",
      "    * 랭체인 튜토리얼 ([https://python.langchain.com/docs/modules/](https://python.langchain.com/docs/modules/))\n",
      "    * 랭체인 관련 블로그 글 (예: [LangChain 시작하기 - Velog](https://velog.io/@sjlee0508/%EB%9E%AD%EC%B2%B8%EC%9D%B8-LangChain-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0))\n",
      "\n",
      "**3주차: 랭체인 RAG 핵심 모듈 학습 (Document Loaders, Text Splitters, Embeddings)**\n",
      "\n",
      "* **목표:** RAG 시스템 구축에 필수적인 랭체인 모듈 (Document Loaders, Text Splitters, Embeddings)의 사용법을 익히고, 데이터 전처리 과정을 이해합니다.\n",
      "* **학습 내용:**\n",
      "    * **Document Loaders**: 다양한 문서 형식 (텍스트, PDF, 웹 페이지 등) 로드 방법 학습\n",
      "    * **Text Splitters**: 텍스트 분할 방식 (Chunking) 및 다양한 Text Splitter 종류 (Character, Recursive, Token 등) 학습 및 실습\n",
      "    * **Embeddings**: 텍스트 임베딩 개념 이해 및 랭체인 Embedding 모델 (OpenAIEmbeddings, HuggingFaceEmbeddings 등) 사용법 학습\n",
      "    * **실제 문서 로드 및 임베딩 생성 실습**:  Document Loaders, Text Splitters, Embeddings 모듈을 연동하여 텍스트 데이터 전처리 파이프라인 구축\n",
      "* **실습 과제:**\n",
      "    * 다양한 Document Loader를 사용하여 여러 형식의 문서 (텍스트 파일, PDF 파일, 웹 페이지 URL 등) 로드해보기\n",
      "    * 다양한 Text Splitter를 적용하여 텍스트 분할 결과 비교 분석\n",
      "    * 랭체인 Embedding 모델을 사용하여 텍스트 임베딩 생성 및 벡터 확인\n",
      "    * 자신이 관심 있는 분야의 문서 (예: 뉴스 기사, 논문 초록 등)를 로드하고 임베딩 생성하는 파이프라인 구축\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Document Loaders ([https://python.langchain.com/docs/modules/data_connection/document_loaders/](https://python.langchain.com/docs/modules/data_connection/document_loaders/))\n",
      "    * 랭체인 공식 문서 - Text Splitters ([https://python.langchain.com/docs/modules/data_connection/document_transformers/](https://python.langchain.com/docs/modules/data_connection/document_transformers/))\n",
      "    * 랭체인 공식 문서 - Embeddings ([https://python.langchain.com/docs/modules/data_connection/text_embedding/](https://python.langchain.com/docs/modules/data_connection/text_embedding/))\n",
      "\n",
      "**4주차: 랭체인 RAG 핵심 모듈 학습 (Vector Stores, Retrievers)**\n",
      "\n",
      "* **목표:**  임베딩된 텍스트 데이터를 효율적으로 저장하고 검색하는 Vector Stores와 Retrievers 모듈의 사용법을 익힙니다. RAG 시스템의 검색(Retrieval) 단계를 구현합니다.\n",
      "* **학습 내용:**\n",
      "    * **Vector Stores**: 벡터 데이터베이스 개념 이해 및 랭체인 Vector Store 종류 (Chroma, FAISS, Pinecone 등) 학습 및 비교\n",
      "    * **Vector Store 구축 및 데이터 저장**:  랭체인 Vector Store를 사용하여 임베딩 벡터 저장 실습\n",
      "    * **Retrievers**:  Vector Store에서 관련 문서 검색하는 다양한 Retriever 종류 (VectorDBQA, SelfQueryRetriever 등) 학습 및 비교\n",
      "    * **Retrieval 실습**:  Retrievers를 사용하여 Vector Store에서 질문과 관련된 문서 검색 및 결과 확인\n",
      "* **실습 과제:**\n",
      "    * 다양한 Vector Store (Chroma, FAISS 등) 중 하나를 선택하여 구축하고, 임베딩된 텍스트 데이터 저장\n",
      "    * 다양한 Retriever를 사용하여 Vector Store에서 특정 질문에 대한 관련 문서 검색 및 검색 결과 비교 분석\n",
      "    * 이전 주차에서 구축한 문서 임베딩 파이프라인과 Vector Store, Retriever를 연동하여 간단한 검색 시스템 구축\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Vector Stores ([https://python.langchain.com/docs/modules/data_connection/vectorstores/](https://python.langchain.com/docs/modules/data_connection/vectorstores/))\n",
      "    * 랭체인 공식 문서 - Retrievers ([https://python.langchain.com/docs/modules/data_connection/retrievers/](https://python.langchain.com/docs/modules/data_connection/retrievers/))\n",
      "    * Chroma Vector Store 공식 문서 ([https://www.trychroma.com/docs/](https://www.trychroma.com/docs/))\n",
      "    * FAISS (Facebook AI Similarity Search) 공식 문서 ([https://faiss.ai/](https://faiss.ai/))\n",
      "\n",
      "**5주차: 랭체인 RAG 파이프라인 구축 및 질의응답 시스템 개발**\n",
      "\n",
      "* **목표:**  지금까지 학습한 랭체인 모듈들을 통합하여 RAG 파이프라인을 구축하고, 질의응답 시스템을 개발합니다. RAG 시스템의 전체적인 흐름을 이해하고 실제 적용 능력을 키웁니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG Chain 구축**:  RetrievalQA Chain, ConversationalRetrievalChain 등 RAG Chain 종류 학습 및 선택\n",
      "    * **RAG 파이프라인 연결**:  Document Loaders, Text Splitters, Embeddings, Vector Stores, Retrievers, LLM을 연결하여 RAG 파이프라인 완성\n",
      "    * **질의응답 시스템 개발**:  RAG 파이프라인을 활용하여 사용자 질문에 답변하는 질의응답 시스템 구축 및 테스트\n",
      "    * **프롬프트 엔지니어링**:  RAG 시스템 성능 향상을 위한 프롬프트 튜닝 기법 학습 및 적용\n",
      "* **실습 과제:**\n",
      "    * 랭체인 RAG Chain (RetrievalQAChain 또는 ConversationalRetrievalChain)을 사용하여 질의응답 시스템 구축\n",
      "    * 사용자 인터페이스 (CLI 또는 간단한 웹 UI)를 추가하여 질의응답 시스템 사용성 향상\n",
      "    * 다양한 질문을 통해 질의응답 시스템 성능 테스트 및 개선점 분석\n",
      "    * 프롬프트 튜닝을 통해 질의응답 시스템의 답변 품질 향상 시도\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Chains ([https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/))\n",
      "    * 랭체인 RAG 예제 코드 ([https://python.langchain.com/docs/use_cases/question_answering/](https://python.langchain.com/docs/use_cases/question_answering/))\n",
      "    * 프롬프트 엔지니어링 가이드 ([https://www.promptingguide.ai/](https://www.promptingguide.ai/))\n",
      "\n",
      "**6주차: RAG 심화 학습 및 활용 사례 탐구, 프로젝트 진행**\n",
      "\n",
      "* **목표:**  RAG 시스템의 성능 향상 기법, 다양한 활용 사례를 학습하고, 개인 프로젝트를 진행하여 RAG 응용 능력을 확장합니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG 성능 향상 기법**:  Reranking, Query Expansion, Metadata Filtering 등 고급 RAG 기술 학습\n",
      "    * **다양한 RAG 활용 사례**:  특정 도메인 (의료, 법률, 금융 등) RAG 적용 사례, 멀티모달 RAG 등 심화된 RAG 활용 방식 탐구\n",
      "    * **RAG 시스템 평가**:  RAG 시스템 성능 평가 지표 (정확도, 관련성, 답변 품질 등) 학습 및 평가 방법 이해\n",
      "    * **개인 프로젝트 기획 및 개발**:  자신만의 RAG 기반 애플리케이션 아이디어 구상 및 개발 시작 (예: 특정 분야 문서 기반 챗봇, 지식 검색 시스템 등)\n",
      "* **실습 과제:**\n",
      "    * RAG 성능 향상 기법 (Reranking, Query Expansion 등) 중 하나를 선택하여 기존 질의응답 시스템에 적용하고 성능 변화 비교 분석\n",
      "    * 관심 있는 분야의 RAG 활용 사례를 조사하고, 랭체인을 사용하여 유사한 시스템 개발 시도\n",
      "    * RAG 시스템 평가 지표를 사용하여 개발한 질의응답 시스템 성능 평가 및 개선 방향 모색\n",
      "    * 개인 프로젝트 계획 구체화 및 개발 시작 (기본 기능 구현 목표)\n",
      "* **참고 자료:**\n",
      "    * RAG 관련 최신 연구 동향 (논문, 기술 블로그 등)\n",
      "    * 랭체인 Agent 기능 학습 ([https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/))\n",
      "    * Langchain Hub ([https://hub.langchain.com/](https://hub.langchain.com/)) - 다양한 랭체인 컴포넌트 및 예제 참고\n",
      "\n",
      "**학습 팁:**\n",
      "\n",
      "* **꾸준함**: 매주 계획된 학습량을 꾸준히 실천하는 것이 중요합니다.\n",
      "* **실습 중심**: 이론 학습과 함께 랭체인 코드를 직접 작성하고 실행해보는 실습 위주 학습을 추천합니다.\n",
      "* **공식 문서 활용**: 랭체인 공식 문서를 적극적으로 활용하여 최신 정보 및 상세 내용을 확인하세요.\n",
      "* **커뮤니티 참여**: 랭체인 관련 커뮤니티 (Stack Overflow, Langchain Discord 채널 등)에 참여하여 질문하고 정보를 공유하며 함께 성장하세요.\n",
      "* **개인 프로젝트**:  학습 내용을 바탕으로 자신만의 RAG 프로젝트를 진행하며 실력 향상을 도모하세요.\n",
      "\n",
      "**추가적으로 궁금한 점이나 필요한 자료가 있다면 언제든지 저에게 문의해주세요!**  즐거운 랭체인 RAG 학습 여정이 되기를 응원합니다!"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import os\n",
    "\n",
    "api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "# 모델 호출\n",
    "study_chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-thinking-exp-01-21\", temperature=0, google_api_key=api_key)\n",
    "\n",
    "# ChatPromptTemplate 통해 스터디 플래너 역할 부여 및 사용자 프롬프트 매개변수화개변수화\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 공부 계획을 세워주는 스터디 플래너 머신입니다.\"\n",
    "                \"사용자의 공부 주제를 입력받으면, 이를 학습하기 위한 공부 계획을 작성합니다.\"\n",
    "            )\n",
    "        ), \n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 설정한 프롬프트 탬플릿에 HumanMessage 전달\n",
    "message = chat_template.format_messages(text=\"랭체인을 활용한 RAG에 대해서 공부하고 싶어요.\")\n",
    "\n",
    "# stream 함수를 통한 답변 스트리밍\n",
    "for chunk in study_chat.stream(message):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 랭체인(LangChain) RAG 학습 계획 (6주)\n",
      "\n",
      "안녕하세요! 랭체인을 활용한 RAG (Retrieval-Augmented Generation) 학습 계획을 수립해 드릴게요. 6주 동안 RAG의 기본 개념부터 랭체인을 활용한 심화 내용까지 체계적으로 학습할 수 있도록 구성했습니다.  각 주차별 목표, 학습 내용, 실습 과제, 참고 자료를 포함하고 있으며, 개인의 학습 속도에 맞춰 조절 가능합니다.\n",
      "\n",
      "**학습 목표:**\n",
      "\n",
      "* RAG의 기본 원리 및 작동 방식 이해\n",
      "* 랭체인의 핵심 모듈 및 기능 숙지\n",
      "* 랭체인을 활용하여 실제 RAG 시스템 구축 능력 함양\n",
      "* 다양한 RAG 활용 사례 학습 및 응용 능력 강화\n",
      "\n",
      "**주차별 학습 계획:**\n",
      "\n",
      "**1주차: RAG 기초 다지기 (RAG 개념 및 필요성 이해)**\n",
      "\n",
      "* **목표:** RAG의 기본적인 개념과 등장 배경, 그리고 왜 필요한 기술인지 이해합니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG란 무엇인가?**: 정의, 작동 방식, 장점 및 단점 학습\n",
      "    * **기존 생성 모델의 한계**:  생성 모델의 환각(Hallucination) 문제점과 RAG의 필요성 이해\n",
      "    * **검색(Retrieval)과 생성(Generation)의 결합**:  각 단계별 역할 및 상호 작용 방식 학습\n",
      "    * **RAG의 다양한 활용 분야**:  챗봇, 문서 요약, 질의응답 등 실제 적용 사례 탐색\n",
      "* **실습 과제:**\n",
      "    * RAG 관련 블로그 글 또는 논문 2-3개 읽고 핵심 내용 요약\n",
      "    * RAG를 활용할 수 있는 아이디어 3가지 이상 발상하고 간단하게 설명\n",
      "* **참고 자료:**\n",
      "    * RAG 관련 블로그 글 (예: [검색 증강 생성(RAG)이란 무엇일까요? - AWS](https://aws.amazon.com/ko/what-is/retrieval-augmented-generation-rag/))\n",
      "    * RAG 관련 유튜브 영상 (예: [RAG(Retrieval Augmented Generation) 쉽게 이해하기](https://www.youtube.com/watch?v=wmddn_gOQ-Y))\n",
      "    * RAG 관련 논문 (예: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks)\n",
      "\n",
      "**2주차: 랭체인(LangChain) 첫걸음 (기본 개념 및 환경 설정)**\n",
      "\n",
      "* **목표:** 랭체인의 기본적인 개념을 이해하고, 학습 환경을 설정합니다. 랭체인의 핵심 모듈과 사용법을 익히기 위한 준비 단계입니다.\n",
      "* **학습 내용:**\n",
      "    * **랭체인 소개**: 랭체인의 특징, 장점, 주요 기능 학습\n",
      "    * **랭체인 설치 및 개발 환경 설정**:  Python 환경 설정, 랭체인 라이브러리 설치\n",
      "    * **랭체인의 기본 구성 요소**:  Models, Prompts, Chains, Indexes, Memory, Agents 등 핵심 모듈 소개 및 역할 이해\n",
      "    * **간단한 랭체인 예제 실행**:  LLM 호출, 프롬프트 템플릿 사용 등 기본적인 랭체인 코드 실습\n",
      "* **실습 과제:**\n",
      "    * 랭체인 개발 환경 설정 완료 (Python, Langchain 라이브러리 설치)\n",
      "    * 랭체인 공식 문서 또는 튜토리얼 따라 간단한 예제 코드 실행 및 결과 확인\n",
      "    * 랭체인 주요 모듈 (Models, Prompts, Chains) 각각의 역할과 간단한 사용법 정리\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 ([https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction))\n",
      "    * 랭체인 튜토리얼 ([https://python.langchain.com/docs/modules/](https://python.langchain.com/docs/modules/))\n",
      "    * 랭체인 관련 블로그 글 (예: [LangChain 시작하기 - Velog](https://velog.io/@sjlee0508/%EB%9E%AD%EC%B2%B8%EC%9D%B8-LangChain-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0))\n",
      "\n",
      "**3주차: 랭체인 RAG 핵심 모듈 학습 (Document Loaders, Text Splitters, Embeddings)**\n",
      "\n",
      "* **목표:** RAG 시스템 구축에 필수적인 랭체인 모듈 (Document Loaders, Text Splitters, Embeddings)의 사용법을 익히고, 데이터 전처리 과정을 이해합니다.\n",
      "* **학습 내용:**\n",
      "    * **Document Loaders**: 다양한 문서 형식 (텍스트, PDF, 웹 페이지 등) 로드 방법 학습\n",
      "    * **Text Splitters**: 텍스트 분할 방식 (Chunking) 및 다양한 Text Splitter 종류 (Character, Recursive, Token 등) 학습 및 실습\n",
      "    * **Embeddings**: 텍스트 임베딩 개념 이해 및 랭체인 Embedding 모델 (OpenAIEmbeddings, HuggingFaceEmbeddings 등) 사용법 학습\n",
      "    * **실제 문서 로드 및 임베딩 생성 실습**:  Document Loaders, Text Splitters, Embeddings 모듈을 연동하여 텍스트 데이터 전처리 파이프라인 구축\n",
      "* **실습 과제:**\n",
      "    * 다양한 Document Loader를 사용하여 여러 형식의 문서 (텍스트 파일, PDF 파일, 웹 페이지 URL 등) 로드해보기\n",
      "    * 다양한 Text Splitter를 적용하여 텍스트 분할 결과 비교 분석\n",
      "    * 랭체인 Embedding 모델을 사용하여 텍스트 임베딩 생성 및 벡터 확인\n",
      "    * 자신이 관심 있는 분야의 문서 (예: 뉴스 기사, 논문 초록 등)를 로드하고 임베딩 생성하는 파이프라인 구축\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Document Loaders ([https://python.langchain.com/docs/modules/data_connection/document_loaders/](https://python.langchain.com/docs/modules/data_connection/document_loaders/))\n",
      "    * 랭체인 공식 문서 - Text Splitters ([https://python.langchain.com/docs/modules/data_connection/document_transformers/](https://python.langchain.com/docs/modules/data_connection/document_transformers/))\n",
      "    * 랭체인 공식 문서 - Embeddings ([https://python.langchain.com/docs/modules/data_connection/text_embedding/](https://python.langchain.com/docs/modules/data_connection/text_embedding/))\n",
      "\n",
      "**4주차: 랭체인 RAG 핵심 모듈 학습 (Vector Stores, Retrievers)**\n",
      "\n",
      "* **목표:**  임베딩된 텍스트 데이터를 효율적으로 저장하고 검색하는 Vector Stores와 Retrievers 모듈의 사용법을 익힙니다. RAG 시스템의 검색(Retrieval) 단계를 구현합니다.\n",
      "* **학습 내용:**\n",
      "    * **Vector Stores**: 벡터 데이터베이스 개념 이해 및 랭체인 Vector Store 종류 (Chroma, FAISS, Pinecone 등) 학습 및 비교\n",
      "    * **Vector Store 구축 및 데이터 저장**:  랭체인 Vector Store를 사용하여 임베딩 벡터 저장 실습\n",
      "    * **Retrievers**:  Vector Store에서 관련 문서 검색하는 다양한 Retriever 종류 (VectorDBQA, SelfQueryRetriever 등) 학습 및 비교\n",
      "    * **Retrieval 실습**:  Retrievers를 사용하여 Vector Store에서 질문과 관련된 문서 검색 및 결과 확인\n",
      "* **실습 과제:**\n",
      "    * 다양한 Vector Store (Chroma, FAISS 등) 중 하나를 선택하여 구축하고, 임베딩된 텍스트 데이터 저장\n",
      "    * 다양한 Retriever를 사용하여 Vector Store에서 특정 질문에 대한 관련 문서 검색 및 검색 결과 비교 분석\n",
      "    * 이전 주차에서 구축한 문서 임베딩 파이프라인과 Vector Store, Retriever를 연동하여 간단한 검색 시스템 구축\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Vector Stores ([https://python.langchain.com/docs/modules/data_connection/vectorstores/](https://python.langchain.com/docs/modules/data_connection/vectorstores/))\n",
      "    * 랭체인 공식 문서 - Retrievers ([https://python.langchain.com/docs/modules/data_connection/retrievers/](https://python.langchain.com/docs/modules/data_connection/retrievers/))\n",
      "    * Chroma Vector Store 공식 문서 ([https://www.trychroma.com/docs/](https://www.trychroma.com/docs/))\n",
      "    * FAISS (Facebook AI Similarity Search) 공식 문서 ([https://faiss.ai/](https://faiss.ai/))\n",
      "\n",
      "**5주차: 랭체인 RAG 파이프라인 구축 및 질의응답 시스템 개발**\n",
      "\n",
      "* **목표:**  지금까지 학습한 랭체인 모듈들을 통합하여 RAG 파이프라인을 구축하고, 질의응답 시스템을 개발합니다. RAG 시스템의 전체적인 흐름을 이해하고 실제 적용 능력을 키웁니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG Chain 구축**:  RetrievalQA Chain, ConversationalRetrievalChain 등 RAG Chain 종류 학습 및 선택\n",
      "    * **RAG 파이프라인 연결**:  Document Loaders, Text Splitters, Embeddings, Vector Stores, Retrievers, LLM을 연결하여 RAG 파이프라인 완성\n",
      "    * **질의응답 시스템 개발**:  RAG 파이프라인을 활용하여 사용자 질문에 답변하는 질의응답 시스템 구축 및 테스트\n",
      "    * **프롬프트 엔지니어링**:  RAG 시스템 성능 향상을 위한 프롬프트 튜닝 기법 학습 및 적용\n",
      "* **실습 과제:**\n",
      "    * 랭체인 RAG Chain (RetrievalQAChain 또는 ConversationalRetrievalChain)을 사용하여 질의응답 시스템 구축\n",
      "    * 사용자 인터페이스 (CLI 또는 간단한 웹 UI)를 추가하여 질의응답 시스템 사용성 향상\n",
      "    * 다양한 질문을 통해 질의응답 시스템 성능 테스트 및 개선점 분석\n",
      "    * 프롬프트 튜닝을 통해 질의응답 시스템의 답변 품질 향상 시도\n",
      "* **참고 자료:**\n",
      "    * 랭체인 공식 문서 - Chains ([https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/))\n",
      "    * 랭체인 RAG 예제 코드 ([https://python.langchain.com/docs/use_cases/question_answering/](https://python.langchain.com/docs/use_cases/question_answering/))\n",
      "    * 프롬프트 엔지니어링 가이드 ([https://www.promptingguide.ai/](https://www.promptingguide.ai/))\n",
      "\n",
      "**6주차: RAG 심화 학습 및 활용 사례 탐구, 프로젝트 진행**\n",
      "\n",
      "* **목표:**  RAG 시스템의 성능 향상 기법, 다양한 활용 사례를 학습하고, 개인 프로젝트를 진행하여 RAG 응용 능력을 확장합니다.\n",
      "* **학습 내용:**\n",
      "    * **RAG 성능 향상 기법**:  Reranking, Query Expansion, Metadata Filtering 등 고급 RAG 기술 학습\n",
      "    * **다양한 RAG 활용 사례**:  특정 도메인 (의료, 법률, 금융 등) RAG 적용 사례, 멀티모달 RAG 등 심화된 RAG 활용 방식 탐구\n",
      "    * **RAG 시스템 평가**:  RAG 시스템 성능 평가 지표 (정확도, 관련성, 답변 품질 등) 학습 및 평가 방법 이해\n",
      "    * **개인 프로젝트 기획 및 개발**:  자신만의 RAG 기반 애플리케이션 아이디어 구상 및 개발 시작 (예: 특정 분야 문서 기반 챗봇, 지식 검색 시스템 등)\n",
      "* **실습 과제:**\n",
      "    * RAG 성능 향상 기법 (Reranking, Query Expansion 등) 중 하나를 선택하여 기존 질의응답 시스템에 적용하고 성능 변화 비교 분석\n",
      "    * 관심 있는 분야의 RAG 활용 사례를 조사하고, 랭체인을 사용하여 유사한 시스템 개발 시도\n",
      "    * RAG 시스템 평가 지표를 사용하여 개발한 질의응답 시스템 성능 평가 및 개선 방향 모색\n",
      "    * 개인 프로젝트 계획 구체화 및 개발 시작 (기본 기능 구현 목표)\n",
      "* **참고 자료:**\n",
      "    * RAG 관련 최신 연구 동향 (논문, 기술 블로그 등)\n",
      "    * 랭체인 Agent 기능 학습 ([https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/))\n",
      "    * Langchain Hub ([https://hub.langchain.com/](https://hub.langchain.com/)) - 다양한 랭체인 컴포넌트 및 예제 참고\n",
      "\n",
      "**학습 팁:**\n",
      "\n",
      "* **꾸준함**: 매주 계획된 학습량을 꾸준히 실천하는 것이 중요합니다.\n",
      "* **실습 중심**: 이론 학습과 함께 랭체인 코드를 직접 작성하고 실행해보는 실습 위주 학습을 추천합니다.\n",
      "* **공식 문서 활용**: 랭체인 공식 문서를 적극적으로 활용하여 최신 정보 및 상세 내용을 확인하세요.\n",
      "* **커뮤니티 참여**: 랭체인 관련 커뮤니티 (Stack Overflow, Langchain Discord 채널 등)에 참여하여 질문하고 정보를 공유하며 함께 성장하세요.\n",
      "* **개인 프로젝트**:  학습 내용을 바탕으로 자신만의 RAG 프로젝트를 진행하며 실력 향상을 도모하세요.\n",
      "\n",
      "**추가적으로 궁금한 점이나 필요한 자료가 있다면 언제든지 저에게 문의해주세요!**  즐거운 랭체인 RAG 학습 여정이 되기를 응원합니다!\n"
     ]
    }
   ],
   "source": [
    "study_answer = study_chat.invoke(message)\n",
    "print(study_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='## 랭체인(LangChain) RAG 학습 계획 (6주)\\n\\n안녕하세요! 랭체인을 활용한 RAG (Retrieval-Augmented Generation) 학습 계획을 수립해 드릴게요. 6주 동안 RAG의 기본 개념부터 랭체인을 활용한 심화 내용까지 체계적으로 학습할 수 있도록 구성했습니다.  각 주차별 목표, 학습 내용, 실습 과제, 참고 자료를 포함하고 있으며, 개인의 학습 속도에 맞춰 조절 가능합니다.\\n\\n**학습 목표:**\\n\\n* RAG의 기본 원리 및 작동 방식 이해\\n* 랭체인의 핵심 모듈 및 기능 숙지\\n* 랭체인을 활용하여 실제 RAG 시스템 구축 능력 함양\\n* 다양한 RAG 활용 사례 학습 및 응용 능력 강화\\n\\n**주차별 학습 계획:**\\n\\n**1주차: RAG 기초 다지기 (RAG 개념 및 필요성 이해)**\\n\\n* **목표:** RAG의 기본적인 개념과 등장 배경, 그리고 왜 필요한 기술인지 이해합니다.\\n* **학습 내용:**\\n    * **RAG란 무엇인가?**: 정의, 작동 방식, 장점 및 단점 학습\\n    * **기존 생성 모델의 한계**:  생성 모델의 환각(Hallucination) 문제점과 RAG의 필요성 이해\\n    * **검색(Retrieval)과 생성(Generation)의 결합**:  각 단계별 역할 및 상호 작용 방식 학습\\n    * **RAG의 다양한 활용 분야**:  챗봇, 문서 요약, 질의응답 등 실제 적용 사례 탐색\\n* **실습 과제:**\\n    * RAG 관련 블로그 글 또는 논문 2-3개 읽고 핵심 내용 요약\\n    * RAG를 활용할 수 있는 아이디어 3가지 이상 발상하고 간단하게 설명\\n* **참고 자료:**\\n    * RAG 관련 블로그 글 (예: [검색 증강 생성(RAG)이란 무엇일까요? - AWS](https://aws.amazon.com/ko/what-is/retrieval-augmented-generation-rag/))\\n    * RAG 관련 유튜브 영상 (예: [RAG(Retrieval Augmented Generation) 쉽게 이해하기](https://www.youtube.com/watch?v=wmddn_gOQ-Y))\\n    * RAG 관련 논문 (예: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks)\\n\\n**2주차: 랭체인(LangChain) 첫걸음 (기본 개념 및 환경 설정)**\\n\\n* **목표:** 랭체인의 기본적인 개념을 이해하고, 학습 환경을 설정합니다. 랭체인의 핵심 모듈과 사용법을 익히기 위한 준비 단계입니다.\\n* **학습 내용:**\\n    * **랭체인 소개**: 랭체인의 특징, 장점, 주요 기능 학습\\n    * **랭체인 설치 및 개발 환경 설정**:  Python 환경 설정, 랭체인 라이브러리 설치\\n    * **랭체인의 기본 구성 요소**:  Models, Prompts, Chains, Indexes, Memory, Agents 등 핵심 모듈 소개 및 역할 이해\\n    * **간단한 랭체인 예제 실행**:  LLM 호출, 프롬프트 템플릿 사용 등 기본적인 랭체인 코드 실습\\n* **실습 과제:**\\n    * 랭체인 개발 환경 설정 완료 (Python, Langchain 라이브러리 설치)\\n    * 랭체인 공식 문서 또는 튜토리얼 따라 간단한 예제 코드 실행 및 결과 확인\\n    * 랭체인 주요 모듈 (Models, Prompts, Chains) 각각의 역할과 간단한 사용법 정리\\n* **참고 자료:**\\n    * 랭체인 공식 문서 ([https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction))\\n    * 랭체인 튜토리얼 ([https://python.langchain.com/docs/modules/](https://python.langchain.com/docs/modules/))\\n    * 랭체인 관련 블로그 글 (예: [LangChain 시작하기 - Velog](https://velog.io/@sjlee0508/%EB%9E%AD%EC%B2%B8%EC%9D%B8-LangChain-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0))\\n\\n**3주차: 랭체인 RAG 핵심 모듈 학습 (Document Loaders, Text Splitters, Embeddings)**\\n\\n* **목표:** RAG 시스템 구축에 필수적인 랭체인 모듈 (Document Loaders, Text Splitters, Embeddings)의 사용법을 익히고, 데이터 전처리 과정을 이해합니다.\\n* **학습 내용:**\\n    * **Document Loaders**: 다양한 문서 형식 (텍스트, PDF, 웹 페이지 등) 로드 방법 학습\\n    * **Text Splitters**: 텍스트 분할 방식 (Chunking) 및 다양한 Text Splitter 종류 (Character, Recursive, Token 등) 학습 및 실습\\n    * **Embeddings**: 텍스트 임베딩 개념 이해 및 랭체인 Embedding 모델 (OpenAIEmbeddings, HuggingFaceEmbeddings 등) 사용법 학습\\n    * **실제 문서 로드 및 임베딩 생성 실습**:  Document Loaders, Text Splitters, Embeddings 모듈을 연동하여 텍스트 데이터 전처리 파이프라인 구축\\n* **실습 과제:**\\n    * 다양한 Document Loader를 사용하여 여러 형식의 문서 (텍스트 파일, PDF 파일, 웹 페이지 URL 등) 로드해보기\\n    * 다양한 Text Splitter를 적용하여 텍스트 분할 결과 비교 분석\\n    * 랭체인 Embedding 모델을 사용하여 텍스트 임베딩 생성 및 벡터 확인\\n    * 자신이 관심 있는 분야의 문서 (예: 뉴스 기사, 논문 초록 등)를 로드하고 임베딩 생성하는 파이프라인 구축\\n* **참고 자료:**\\n    * 랭체인 공식 문서 - Document Loaders ([https://python.langchain.com/docs/modules/data_connection/document_loaders/](https://python.langchain.com/docs/modules/data_connection/document_loaders/))\\n    * 랭체인 공식 문서 - Text Splitters ([https://python.langchain.com/docs/modules/data_connection/document_transformers/](https://python.langchain.com/docs/modules/data_connection/document_transformers/))\\n    * 랭체인 공식 문서 - Embeddings ([https://python.langchain.com/docs/modules/data_connection/text_embedding/](https://python.langchain.com/docs/modules/data_connection/text_embedding/))\\n\\n**4주차: 랭체인 RAG 핵심 모듈 학습 (Vector Stores, Retrievers)**\\n\\n* **목표:**  임베딩된 텍스트 데이터를 효율적으로 저장하고 검색하는 Vector Stores와 Retrievers 모듈의 사용법을 익힙니다. RAG 시스템의 검색(Retrieval) 단계를 구현합니다.\\n* **학습 내용:**\\n    * **Vector Stores**: 벡터 데이터베이스 개념 이해 및 랭체인 Vector Store 종류 (Chroma, FAISS, Pinecone 등) 학습 및 비교\\n    * **Vector Store 구축 및 데이터 저장**:  랭체인 Vector Store를 사용하여 임베딩 벡터 저장 실습\\n    * **Retrievers**:  Vector Store에서 관련 문서 검색하는 다양한 Retriever 종류 (VectorDBQA, SelfQueryRetriever 등) 학습 및 비교\\n    * **Retrieval 실습**:  Retrievers를 사용하여 Vector Store에서 질문과 관련된 문서 검색 및 결과 확인\\n* **실습 과제:**\\n    * 다양한 Vector Store (Chroma, FAISS 등) 중 하나를 선택하여 구축하고, 임베딩된 텍스트 데이터 저장\\n    * 다양한 Retriever를 사용하여 Vector Store에서 특정 질문에 대한 관련 문서 검색 및 검색 결과 비교 분석\\n    * 이전 주차에서 구축한 문서 임베딩 파이프라인과 Vector Store, Retriever를 연동하여 간단한 검색 시스템 구축\\n* **참고 자료:**\\n    * 랭체인 공식 문서 - Vector Stores ([https://python.langchain.com/docs/modules/data_connection/vectorstores/](https://python.langchain.com/docs/modules/data_connection/vectorstores/))\\n    * 랭체인 공식 문서 - Retrievers ([https://python.langchain.com/docs/modules/data_connection/retrievers/](https://python.langchain.com/docs/modules/data_connection/retrievers/))\\n    * Chroma Vector Store 공식 문서 ([https://www.trychroma.com/docs/](https://www.trychroma.com/docs/))\\n    * FAISS (Facebook AI Similarity Search) 공식 문서 ([https://faiss.ai/](https://faiss.ai/))\\n\\n**5주차: 랭체인 RAG 파이프라인 구축 및 질의응답 시스템 개발**\\n\\n* **목표:**  지금까지 학습한 랭체인 모듈들을 통합하여 RAG 파이프라인을 구축하고, 질의응답 시스템을 개발합니다. RAG 시스템의 전체적인 흐름을 이해하고 실제 적용 능력을 키웁니다.\\n* **학습 내용:**\\n    * **RAG Chain 구축**:  RetrievalQA Chain, ConversationalRetrievalChain 등 RAG Chain 종류 학습 및 선택\\n    * **RAG 파이프라인 연결**:  Document Loaders, Text Splitters, Embeddings, Vector Stores, Retrievers, LLM을 연결하여 RAG 파이프라인 완성\\n    * **질의응답 시스템 개발**:  RAG 파이프라인을 활용하여 사용자 질문에 답변하는 질의응답 시스템 구축 및 테스트\\n    * **프롬프트 엔지니어링**:  RAG 시스템 성능 향상을 위한 프롬프트 튜닝 기법 학습 및 적용\\n* **실습 과제:**\\n    * 랭체인 RAG Chain (RetrievalQAChain 또는 ConversationalRetrievalChain)을 사용하여 질의응답 시스템 구축\\n    * 사용자 인터페이스 (CLI 또는 간단한 웹 UI)를 추가하여 질의응답 시스템 사용성 향상\\n    * 다양한 질문을 통해 질의응답 시스템 성능 테스트 및 개선점 분석\\n    * 프롬프트 튜닝을 통해 질의응답 시스템의 답변 품질 향상 시도\\n* **참고 자료:**\\n    * 랭체인 공식 문서 - Chains ([https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/))\\n    * 랭체인 RAG 예제 코드 ([https://python.langchain.com/docs/use_cases/question_answering/](https://python.langchain.com/docs/use_cases/question_answering/))\\n    * 프롬프트 엔지니어링 가이드 ([https://www.promptingguide.ai/](https://www.promptingguide.ai/))\\n\\n**6주차: RAG 심화 학습 및 활용 사례 탐구, 프로젝트 진행**\\n\\n* **목표:**  RAG 시스템의 성능 향상 기법, 다양한 활용 사례를 학습하고, 개인 프로젝트를 진행하여 RAG 응용 능력을 확장합니다.\\n* **학습 내용:**\\n    * **RAG 성능 향상 기법**:  Reranking, Query Expansion, Metadata Filtering 등 고급 RAG 기술 학습\\n    * **다양한 RAG 활용 사례**:  특정 도메인 (의료, 법률, 금융 등) RAG 적용 사례, 멀티모달 RAG 등 심화된 RAG 활용 방식 탐구\\n    * **RAG 시스템 평가**:  RAG 시스템 성능 평가 지표 (정확도, 관련성, 답변 품질 등) 학습 및 평가 방법 이해\\n    * **개인 프로젝트 기획 및 개발**:  자신만의 RAG 기반 애플리케이션 아이디어 구상 및 개발 시작 (예: 특정 분야 문서 기반 챗봇, 지식 검색 시스템 등)\\n* **실습 과제:**\\n    * RAG 성능 향상 기법 (Reranking, Query Expansion 등) 중 하나를 선택하여 기존 질의응답 시스템에 적용하고 성능 변화 비교 분석\\n    * 관심 있는 분야의 RAG 활용 사례를 조사하고, 랭체인을 사용하여 유사한 시스템 개발 시도\\n    * RAG 시스템 평가 지표를 사용하여 개발한 질의응답 시스템 성능 평가 및 개선 방향 모색\\n    * 개인 프로젝트 계획 구체화 및 개발 시작 (기본 기능 구현 목표)\\n* **참고 자료:**\\n    * RAG 관련 최신 연구 동향 (논문, 기술 블로그 등)\\n    * 랭체인 Agent 기능 학습 ([https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/))\\n    * Langchain Hub ([https://hub.langchain.com/](https://hub.langchain.com/)) - 다양한 랭체인 컴포넌트 및 예제 참고\\n\\n**학습 팁:**\\n\\n* **꾸준함**: 매주 계획된 학습량을 꾸준히 실천하는 것이 중요합니다.\\n* **실습 중심**: 이론 학습과 함께 랭체인 코드를 직접 작성하고 실행해보는 실습 위주 학습을 추천합니다.\\n* **공식 문서 활용**: 랭체인 공식 문서를 적극적으로 활용하여 최신 정보 및 상세 내용을 확인하세요.\\n* **커뮤니티 참여**: 랭체인 관련 커뮤니티 (Stack Overflow, Langchain Discord 채널 등)에 참여하여 질문하고 정보를 공유하며 함께 성장하세요.\\n* **개인 프로젝트**:  학습 내용을 바탕으로 자신만의 RAG 프로젝트를 진행하며 실력 향상을 도모하세요.\\n\\n**추가적으로 궁금한 점이나 필요한 자료가 있다면 언제든지 저에게 문의해주세요!**  즐거운 랭체인 RAG 학습 여정이 되기를 응원합니다!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-cc50697b-f632-47cd-9761-a6a4ad7cd066-0' usage_metadata={'input_tokens': 66, 'output_tokens': 3094, 'total_tokens': 3160, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(study_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
